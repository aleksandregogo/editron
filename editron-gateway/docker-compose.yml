version: '3.8'

services:
  db:
    image: pgvector/pgvector:pg15
    ports:
      - "5433:5432"
    environment:
      POSTGRES_USER: kukumala
      POSTGRES_PASSWORD: abduljabarkhani
      POSTGRES_DB: editron
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - socket-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kukumala -d editron"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - socket-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: ./
      dockerfile: ./Dockerfile.backend
    command: npm run start:dev
    ports:
      - "5000:5000"
    networks:
      - socket-network
    environment:
      DB_HOST: db
      DB_PORT: 5432
      DB_USERNAME: kukumala
      DB_PASSWORD: abduljabarkhani
      DB_NAME: editron
      REDIS_HOST: redis
      REDIS_PORT: 6379
      # Cloudflare AI Gateway Configuration (matching reference implementation)
      CLOUDFLARE_ACCOUNT_ID: ${CLOUDFLARE_ACCOUNT_ID}
      CLOUDFLARE_GATEWAY_TOKEN: ${CLOUDFLARE_GATEWAY_TOKEN}
      CLOUDFLARE_WORKER_TOKEN: ${CLOUDFLARE_WORKER_TOKEN}
      CLOUDFLARE_GATEWAY_SLUG: ${CLOUDFLARE_GATEWAY_SLUG:-editron-ai}
      CLOUDFLARE_EMBEDDING_MODEL_ID: ${CLOUDFLARE_EMBEDDING_MODEL_ID}
      CLOUDFLARE_LLM_MODEL_ID: ${CLOUDFLARE_LLM_MODEL_ID}
      # OpenAI Configuration for GPT-4 Turbo
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_CHAT_MODEL_ID: ${OPENAI_CHAT_MODEL_ID:-gpt-4-turbo-preview}
    volumes:
      - ./:/app
      - /app/node_modules
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy

networks:
  socket-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data: